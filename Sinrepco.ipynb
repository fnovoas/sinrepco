{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fnovoas/sinrepco/blob/main/Sinrepco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SINREPCO\n",
        "por fnovoas@unal.edu.co"
      ],
      "metadata": {
        "id": "L3tPnZ558pQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cargar un modelo de Sinrepco ya hecho (entrenado), saltamos directamente al **paso 8**. Podemos evaluarlo en el **paso 6**."
      ],
      "metadata": {
        "id": "znIPoKDs4Nk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Instalamos las bibliotecas necesarias: TensorFlow para el desarrollo de modelos de inteligencia artificial, OpenCV para el procesamiento de imágenes y Tesseract para el reconocimiento óptico de caracteres (OCR)."
      ],
      "metadata": {
        "id": "VSwHf7ak8b99"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQvguu1Q6a7a"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow opencv-python pytesseract"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Procedemos con la recolección de datos, reunimos un conjunto de datos que contiene imágenes de vehículos, tanto contaminantes como no contaminantes, estas imágenes fueron capturadas por mí en diversas ubicaciones. Contamos con 3396 imágenes de vehículos no chimenea y 298 imágenes de vehículos chimenea.\n",
        "Separamos las imágenes según si contienen vehículos que emiten humo visible o no, en dos carpetas: \"chimenea\" y \"no_chimenea\". Con estos datos entrenaremos al modelo.\\\n",
        "Montamos Drive para acceder a las imágenes."
      ],
      "metadata": {
        "id": "mkPe4Udv9xZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar el Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Directorio base donde está la carpeta \"sinrepco_fotos\"\n",
        "base_dir = \"/content/drive/My Drive/sinrepco_fotos\"\n",
        "\n",
        "# Función para contar archivos en una carpeta\n",
        "def contar_archivos_en_carpeta(carpeta):\n",
        "    return len([f for f in os.listdir(carpeta) if os.path.isfile(os.path.join(carpeta, f))])\n",
        "\n",
        "# Recorrer todas las carpetas y subcarpetas en el directorio base\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    for dir_name in dirs:\n",
        "        carpeta_actual = os.path.join(root, dir_name)\n",
        "        num_archivos = contar_archivos_en_carpeta(carpeta_actual)\n",
        "        print(f\"Carpeta encontrada: {carpeta_actual} - Archivos: {num_archivos}\")\n",
        "\n",
        "# Función para cambiar extensión .JPG a .jpg\n",
        "def cambiar_extensiones_a_minusculas(carpeta):\n",
        "    for filename in os.listdir(carpeta):\n",
        "        if filename.endswith(\".JPG\"):\n",
        "            os.rename(os.path.join(carpeta, filename), os.path.join(carpeta, filename.lower()))\n",
        "\n",
        "# Verificar si existe la carpeta 'train' en la raíz\n",
        "if os.path.exists(f'{base_dir}/train'):\n",
        "    # Aplicar cambio de extensiones a las subcarpetas dentro de 'train'\n",
        "    cambiar_extensiones_a_minusculas(f'{base_dir}/train/chimenea')\n",
        "    cambiar_extensiones_a_minusculas(f'{base_dir}/train/no_chimenea')\n",
        "    # Verificar cuántas imágenes hay en cada subcarpeta dentro de 'train'\n",
        "    print(\"Extensión de archivos cambiada de .JPG a .jpg\")\n",
        "    print(f\"Imágenes en train/chimenea: {len(os.listdir(f'{base_dir}/train/chimenea'))}\")\n",
        "    print(f\"Imágenes en train/no_chimenea: {len(os.listdir(f'{base_dir}/train/no_chimenea'))}\")\n",
        "else:\n",
        "    # Aplicar cambio de extensiones en la raíz\n",
        "    cambiar_extensiones_a_minusculas(f'{base_dir}/chimenea')\n",
        "    cambiar_extensiones_a_minusculas(f'{base_dir}/no_chimenea')\n",
        "    # Verificar cuántas imágenes hay en cada carpeta en la raíz\n",
        "    print(\"Extensión de archivos cambiada de .JPG a .jpg\")\n",
        "    print(f\"Imágenes en chimenea: {len(os.listdir(f'{base_dir}/chimenea'))}\")\n",
        "    print(f\"Imágenes en no_chimenea: {len(os.listdir(f'{base_dir}/no_chimenea'))}\")"
      ],
      "metadata": {
        "id": "Fs2QnY1LnLWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importamos las bibliotecas necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "d3OhO9RXnaAR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 3.a. **(Solo hace falta ejecutar este código cada vez que incorporemos nuevos datos, al hacerlo, deben estar guardados en las carpetas originales \"chimenea\" y \"no_chimenea\" en el directorio raíz respectivamente)** Cargamos y preparamos los datos de la carpeta en donde están almacenados en Drive. Este código divide las imágenes en conjuntos de entrenamiento, validación y prueba según el porcentaje especificado: el 70% de los datos irán en entrenamiento y el 15% en cada una de las otras dos categorías. Ejecutar este código cambia la estructura de la organización de los archivos y carpetas en Drive (el cambio tarda unos minutos en reflejarse en Drive)."
      ],
      "metadata": {
        "id": "4fB5L0_InkqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "# Crear directorios si no existen\n",
        "base_dir = '/content/drive/My Drive/sinrepco_fotos'\n",
        "source_chimenea = f'{base_dir}/chimenea'\n",
        "source_no_chimenea = f'{base_dir}/no_chimenea'\n",
        "\n",
        "train_chimenea_dir = f'{base_dir}/train/chimenea'\n",
        "val_chimenea_dir = f'{base_dir}/validation/chimenea'\n",
        "test_chimenea_dir = f'{base_dir}/test/chimenea'\n",
        "\n",
        "train_no_chimenea_dir = f'{base_dir}/train/no_chimenea'\n",
        "val_no_chimenea_dir = f'{base_dir}/validation/no_chimenea'\n",
        "test_no_chimenea_dir = f'{base_dir}/test/no_chimenea'\n",
        "\n",
        "os.makedirs(train_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(val_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(test_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(train_no_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(val_no_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(test_no_chimenea_dir, exist_ok=True)\n",
        "\n",
        "def move_files(files, source, destination):\n",
        "    for f in files:\n",
        "        src_path = os.path.join(source, f)\n",
        "        dest_path = os.path.join(destination, f)\n",
        "        shutil.move(src_path, dest_path)\n",
        "        # Verifica si el archivo se movió correctamente\n",
        "        if not os.path.exists(dest_path):\n",
        "            print(f\"Reintentando mover: {f}\")\n",
        "            shutil.move(src_path, dest_path)\n",
        "            # Da tiempo al sistema para procesar la operación\n",
        "            time.sleep(0.1)\n",
        "\n",
        "def move_data(SOURCE, TRAINING, VALIDATION, TEST, split_train=0.7, split_val_test=0.15):\n",
        "    files = [f for f in os.listdir(SOURCE) if os.path.isfile(os.path.join(SOURCE, f))]\n",
        "    print(f\"Total de archivos encontrados en {SOURCE}: {len(files)}\")  # Imprime el número total de archivos encontrados\n",
        "\n",
        "    random.shuffle(files)\n",
        "\n",
        "    train_size = int(len(files) * split_train)\n",
        "    val_size = int(len(files) * split_val_test)\n",
        "\n",
        "    train_files = files[:train_size]\n",
        "    val_files = files[train_size:train_size + val_size]\n",
        "    test_files = files[train_size + val_size:]\n",
        "\n",
        "    print(f\"Moviendo {len(train_files)} archivos a {TRAINING}\")  # Imprime cuántos archivos se moverán al entrenamiento\n",
        "    print(f\"Moviendo {len(val_files)} archivos a {VALIDATION}\")  # Imprime cuántos archivos se moverán a validación\n",
        "    print(f\"Moviendo {len(test_files)} archivos a {TEST}\")  # Imprime cuántos archivos se moverán a prueba\n",
        "\n",
        "    # Mueve los archivos en lotes para evitar problemas con demasiadas operaciones a la vez\n",
        "    batch_size = 100  # Ajusta este tamaño según sea necesario\n",
        "    for i in range(0, len(train_files), batch_size):\n",
        "        move_files(train_files[i:i+batch_size], SOURCE, TRAINING)\n",
        "\n",
        "    for i in range(0, len(val_files), batch_size):\n",
        "        move_files(val_files[i:i+batch_size], SOURCE, VALIDATION)\n",
        "\n",
        "    for i in range(0, len(test_files), batch_size):\n",
        "        move_files(test_files[i:i+batch_size], SOURCE, TEST)\n",
        "\n",
        "# Ejecutar esta función para cada clase\n",
        "move_data(source_chimenea, train_chimenea_dir, val_chimenea_dir, test_chimenea_dir)\n",
        "move_data(source_no_chimenea, train_no_chimenea_dir, val_no_chimenea_dir, test_no_chimenea_dir)"
      ],
      "metadata": {
        "id": "twbvWtshnngg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.a.1. Creamos una subcarpeta adicional dentro de cada una de las subcarpetas \"chimenea\" y \"no_chimenea\" de la carpeta \"train\", y movemos las imágenes ahí. Esto es para que la función flow_from_directory pueda leer los archivos."
      ],
      "metadata": {
        "id": "OKnnxOMNyvfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una estructura de subcarpetas para chimenea y no_chimenea\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Crear subcarpeta dentro de chimenea\n",
        "os.makedirs(f'{base_dir}/train/chimenea/clase_chimenea', exist_ok=True)\n",
        "for filename in os.listdir(f'{base_dir}/train/chimenea'):\n",
        "    shutil.move(os.path.join(f'{base_dir}/train/chimenea', filename), os.path.join(f'{base_dir}/train/chimenea/clase_chimenea', filename))\n",
        "\n",
        "# Crear subcarpeta dentro de no_chimenea\n",
        "os.makedirs(f'{base_dir}/train/no_chimenea/clase_no_chimenea', exist_ok=True)\n",
        "for filename in os.listdir(f'{base_dir}/train/no_chimenea'):\n",
        "    shutil.move(os.path.join(f'{base_dir}/train/no_chimenea', filename), os.path.join(f'{base_dir}/train/no_chimenea/clase_no_chimenea', filename))"
      ],
      "metadata": {
        "id": "7VViXSTYzHAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.b. Después de dividir los datos, configuramos el ImageDataGenerator para cargar las imágenes de estas nuevas carpetas.  \n",
        "**Actualización**: para compensar la falta de fotos en la carpeta chimenea, usaremos aumento de datos en la clase minoritaria (chimenea) para generar nuevas imágenes variadas de forma sintética. Usamos rotaciones, zoom, traslaciones, cambios de brillo, entre otros.\n",
        "Naturalmente, revertiremos este cambio una vez que hayamos aumentado la cantidad de datos de vehículos chimenea (esto es, cuando les tome más fotos), y no dejaremos imágenes generadas sintéticamente."
      ],
      "metadata": {
        "id": "8yMhhElw4is4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importamos las bibliotecas necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Import the ImageDataGenerator class\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Parámetros (reducir estos valores si nos quedamos sin RAM)\n",
        "IMG_HEIGHT = 450\n",
        "IMG_WIDTH = 600\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# Aumento de datos para la clase chimenea\n",
        "chimenea_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Sin aumento de datos para la clase no_chimenea\n",
        "no_chimenea_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generador para la clase chimenea\n",
        "chimenea_generator = chimenea_datagen.flow_from_directory(\n",
        "    f'{base_dir}/train',\n",
        "    classes=['chimenea/clase_chimenea'],  # Apuntar a la subcarpeta dentro de train\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Generador para la clase no_chimenea\n",
        "no_chimenea_generator = no_chimenea_datagen.flow_from_directory(\n",
        "    f'{base_dir}/train',\n",
        "    classes=['no_chimenea/clase_no_chimenea'],  # Apuntar a la subcarpeta dentro de train\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "# Verificar el generador de la clase chimenea\n",
        "chimenea_images, chimenea_labels = next(chimenea_generator)\n",
        "print(f'Imágenes de chimenea: {chimenea_images.shape}')\n",
        "print(f'Etiquetas de chimenea: {chimenea_labels.shape}')\n",
        "\n",
        "# Verificar el generador de la clase no_chimenea\n",
        "no_chimenea_images, no_chimenea_labels = next(no_chimenea_generator)\n",
        "print(f'Imágenes de no_chimenea: {no_chimenea_images.shape}')\n",
        "print(f'Etiquetas de no_chimenea: {no_chimenea_labels.shape}')\n",
        "\n",
        "# Combinar los generadores\n",
        "def combined_generator(chimenea_gen, no_chimenea_gen):\n",
        "    while True:\n",
        "        chimenea_batch = next(chimenea_gen)\n",
        "        no_chimenea_batch = next(no_chimenea_gen)\n",
        "        combined_images = np.concatenate((chimenea_batch[0], no_chimenea_batch[0]))\n",
        "        combined_labels = np.concatenate((chimenea_batch[1], no_chimenea_batch[1]))\n",
        "        yield combined_images, combined_labels\n",
        "\n",
        "# Generador combinado para entrenamiento\n",
        "train_generator = combined_generator(chimenea_generator, no_chimenea_generator)\n",
        "\n",
        "# Generador de validación (sin aumento)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    f'{base_dir}/validation',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Generador de prueba (sin aumento)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    f'{base_dir}/test',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "test_images, test_labels = next(test_generator)\n",
        "print(f'Imágenes: {test_images.shape}')\n",
        "print(f'Etiquetas: {test_labels.shape}')"
      ],
      "metadata": {
        "id": "TcdEMJal4j_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Ahora definimos la arquitectura de la CNN. Tomamos una estructura de red neuronal convolucional, que es adecuada para el análisis de imágenes."
      ],
      "metadata": {
        "id": "DsbjWUhxNg3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Input\n",
        "\n",
        "# Definir la arquitectura de la CNN\n",
        "model = Sequential([\n",
        "    Input(shape=(450, 600, 3)),  # Especificamos la forma de entrada aquí\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1jK4njrJNjfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Entrenamos** el modelo. Si bien el número de épocas recomendado normalmente (el número de veces que el modelo recorre todo el conjunto de datos para entrenarse) es de 20, usamos 5 para ajustarnos con el tiempo de ejecución máximo disponible (*ejecutar este código puede tomar de 6 a 11 horas, como se ha visto en diferentes iteraciones*).\n",
        "**Actualización**: añadimos el parámetro steps_per_epoch para que se generen nuevas imágenes de la clase \"chimenea\" como explicamos en el punto 3.b."
      ],
      "metadata": {
        "id": "aCGkIbuxlLDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "# Calcular steps_per_epoch\n",
        "total_chimenea = chimenea_generator.samples\n",
        "total_no_chimenea = no_chimenea_generator.samples\n",
        "total_images_in_train = total_chimenea + total_no_chimenea\n",
        "steps_per_epoch = 100  # Reducido temporalmente para depuración\n",
        "\n",
        "# Verificar el generador de la clase chimenea\n",
        "chimenea_images, chimenea_labels = next(chimenea_generator)\n",
        "print(f'Imágenes de chimenea: {chimenea_images.shape}')\n",
        "print(f'Etiquetas de chimenea: {chimenea_labels.shape}')\n",
        "\n",
        "# Verificar el generador de la clase no_chimenea\n",
        "no_chimenea_images, no_chimenea_labels = next(no_chimenea_generator)\n",
        "print(f'Imágenes de no_chimenea: {no_chimenea_images.shape}')\n",
        "print(f'Etiquetas de no_chimenea: {no_chimenea_labels.shape}')\n",
        "\n",
        "# Verificar lo que genera el train_generator\n",
        "images, labels = next(train_generator)\n",
        "print(f'Imágenes: {images.shape}')\n",
        "print(f'Etiquetas: {labels.shape}')\n",
        "print(f'Primera etiqueta: {labels[0]}')\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "id": "F43Er4cLlNNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Evaluamos** el modelo.\n",
        "6.a. Gráficas de pérdida y precisión (*accuracy*)."
      ],
      "metadata": {
        "id": "vc5hRUmtlPQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Graficar los resultados del entrenamiento\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rbBEyXaXlUPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.b. Gráfica de matriz de confusión."
      ],
      "metadata": {
        "id": "5tf0rK4s3j5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Obtener predicciones del conjunto de prueba\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred = np.round(y_pred).astype(int).flatten()  # Redondear a 0 o 1\n",
        "\n",
        "# Obtener etiquetas verdaderas\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Etiquetas de las clases\n",
        "class_names = ['no_chimenea', 'chimenea']\n",
        "\n",
        "# Graficar la matriz de confusión\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pGhP9w5c3o4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.c. Curvas ROC y AUC."
      ],
      "metadata": {
        "id": "jWLPScBk3wnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Obtener probabilidades predichas\n",
        "y_pred_prob = model.predict(test_generator).flatten()\n",
        "\n",
        "# Calcular la curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Graficar la curva ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CCVS6zMU31cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.d. Reporte de clasificación."
      ],
      "metadata": {
        "id": "pTMt_ZbX32-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "id": "XRuFHQaW37XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.e. Curvas de pérdida y precisión **por época**."
      ],
      "metadata": {
        "id": "uKeiAnAh38dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lspWSryh4A6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.f. Gráfica de Precision-Recall"
      ],
      "metadata": {
        "id": "rx4WSZwi4EC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_true, y_pred_prob)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label='Precision-Recall curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N8TfjVXp4G5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Guardar** el modelo ya entrenado en Drive (para no tener que ejecutar el paso 5 nuevamente). *Tamaño del modelo actual: 2.89 GB*."
      ],
      "metadata": {
        "id": "lJVN2KdDnwNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo en formato Keras nativo en la carpeta sinrepco_fotos en Drive\n",
        "model_path = '/content/drive/My Drive/sinrepco_fotos/saved_model.keras'\n",
        "\n",
        "# Guardar el modelo entrenado en la ruta especificada\n",
        "model.save(model_path)\n"
      ],
      "metadata": {
        "id": "skpTlsO9n4YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.a. Descargar el modelo en el equipo local (más demorado)."
      ],
      "metadata": {
        "id": "XHNE5DpRsHE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo en formato Keras nativo en el almacenamiento local de Colab\n",
        "model_path = '/content/saved_model.keras'\n",
        "\n",
        "# Guardar el modelo entrenado en la ruta especificada\n",
        "model.save(model_path)\n",
        "\n",
        "# Descargar el modelo a tu equipo\n",
        "from google.colab import files\n",
        "files.download(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mmyVFH0UsQHg",
        "outputId": "b9f9541e-2f81-413f-9759-6b39477b0227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fb092a35-cfc3-4401-a5e6-6348e9741b17\", \"saved_model.keras\", 3101288695)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Cargar** el modelo a la sesión actual (para usar un modelo guardado anteriormente)."
      ],
      "metadata": {
        "id": "RjwAsyrcoBCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Cargar el modelo guardado\n",
        "model = load_model('/content/drive/My Drive/sinrepco_fotos/saved_model.keras')"
      ],
      "metadata": {
        "id": "IxFnr9Z5oKdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A continuación\n",
        "Deberemos desarrollar el subsistema de reconocimiento de placas vehiculares. Para un futuro avance, deberemos integrar los dos subsistemas y desarrollar la función de publicación automatizada en X (antes Twitter).\n",
        "Gracias por leer."
      ],
      "metadata": {
        "id": "IP46s_n7AiZr"
      }
    }
  ]
}