{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fnovoas/sinrepco/blob/main/Sinrepco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SINREPCO\n",
        "por fnovoas@unal.edu.co"
      ],
      "metadata": {
        "id": "L3tPnZ558pQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cargar un modelo de Sinrepco ya hecho (entrenado), saltamos directamente al **paso 8**. Podemos evaluarlo en el **paso 6**."
      ],
      "metadata": {
        "id": "znIPoKDs4Nk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Instalamos las bibliotecas necesarias: TensorFlow para el desarrollo de modelos de inteligencia artificial, OpenCV para el procesamiento de imágenes y Tesseract para el reconocimiento óptico de caracteres (OCR)."
      ],
      "metadata": {
        "id": "VSwHf7ak8b99"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQvguu1Q6a7a",
        "outputId": "4bad72cd-ffee-46e6-8d12-84c94acee69f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow opencv-python pytesseract"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Procedemos con la recolección de datos, reunimos un conjunto de datos que contiene imágenes de vehículos, tanto contaminantes como no contaminantes, estas imágenes fueron capturadas por mí en diversas ubicaciones. Contamos con 3381 imágenes de vehículos no chimenea y 280 imágenes de vehículos chimenea.\n",
        "Separamos las imágenes según si contienen vehículos que emiten humo visible o no, en dos carpetas: \"chimenea\" y \"no_chimenea\". Con estos datos entrenaremos al modelo.\\\n",
        "Montamos Drive para acceder a las imágenes.\n",
        "**Actualización**: dado que probar añadir peso a las clases para compensar el desequilibrio en la cantidad de fotos de ambas carpetas no funcionó a la hora de intentar conseguir números mayores en la diagonal de la matriz de confusión ([*paso 6.b*](https://github.com/fnovoas/sinrepco/blob/3c774b69f4f4a391a0245498577fdaa3f9d70e65/Sinrepco.ipynb)), esta vez modificamos la carpeta \"chimenea\", copiando y pegando sus 280 elementos 11 veces en sí misma para obtener un total de 3360 elementos (un número cercano a los 3381 elementos de su contraparte). Naturalmente, revertiremos este cambio una vez que hayamos aumentado la cantidad de datos de vehículos chimenea (esto es, cuando les tome más fotos), y no dejaremos imágenes copiadas."
      ],
      "metadata": {
        "id": "mkPe4Udv9xZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar el Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Directorio base donde está la carpeta \"sinrepco_fotos\"\n",
        "base_dir = \"/content/drive/My Drive/sinrepco_fotos\"\n",
        "\n",
        "# Función para contar archivos en una carpeta\n",
        "def contar_archivos_en_carpeta(carpeta):\n",
        "    return len([f for f in os.listdir(carpeta) if os.path.isfile(os.path.join(carpeta, f))])\n",
        "\n",
        "# Recorrer todas las carpetas y subcarpetas en el directorio base\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    for dir_name in dirs:\n",
        "        carpeta_actual = os.path.join(root, dir_name)\n",
        "        num_archivos = contar_archivos_en_carpeta(carpeta_actual)\n",
        "        print(f\"Carpeta encontrada: {carpeta_actual} - Archivos: {num_archivos}\")"
      ],
      "metadata": {
        "id": "Fs2QnY1LnLWe",
        "outputId": "36493de0-7ac0-4566-8a56-4342d690be21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/chimenea - Archivos: 0\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/no_chimenea - Archivos: 0\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/train - Archivos: 0\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/validation - Archivos: 0\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/test - Archivos: 0\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/train/chimenea - Archivos: 2352\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/train/no_chimenea - Archivos: 2366\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/validation/chimenea - Archivos: 504\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/validation/no_chimenea - Archivos: 507\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/test/chimenea - Archivos: 504\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/test/no_chimenea - Archivos: 508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importamos las bibliotecas necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "d3OhO9RXnaAR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 3.a. **(Solo hace falta ejecutar este código cada vez que incorporemos nuevos datos, al hacerlo, deben estar guardados en las carpetas originales \"chimenea\" y \"no_chimenea\" en el directorio raíz respectivamente)** Cargamos y preparamos los datos de la carpeta en donde están almacenados en Drive. Este código divide las imágenes en conjuntos de entrenamiento, validación y prueba según el porcentaje especificado: el 70% de los datos irán en entrenamiento y el 15% en cada una de las otras dos categorías. Ejecutar este código cambia la estructura de la organización de los archivos y carpetas en Drive (el cambio tarda unos minutos en reflejarse en Drive)."
      ],
      "metadata": {
        "id": "4fB5L0_InkqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "# Crear directorios si no existen\n",
        "base_dir = '/content/drive/My Drive/sinrepco_fotos'\n",
        "source_chimenea = f'{base_dir}/chimenea'\n",
        "source_no_chimenea = f'{base_dir}/no_chimenea'\n",
        "\n",
        "train_chimenea_dir = f'{base_dir}/train/chimenea'\n",
        "val_chimenea_dir = f'{base_dir}/validation/chimenea'\n",
        "test_chimenea_dir = f'{base_dir}/test/chimenea'\n",
        "\n",
        "train_no_chimenea_dir = f'{base_dir}/train/no_chimenea'\n",
        "val_no_chimenea_dir = f'{base_dir}/validation/no_chimenea'\n",
        "test_no_chimenea_dir = f'{base_dir}/test/no_chimenea'\n",
        "\n",
        "os.makedirs(train_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(val_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(test_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(train_no_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(val_no_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(test_no_chimenea_dir, exist_ok=True)\n",
        "\n",
        "def move_files(files, source, destination):\n",
        "    for f in files:\n",
        "        src_path = os.path.join(source, f)\n",
        "        dest_path = os.path.join(destination, f)\n",
        "        shutil.move(src_path, dest_path)\n",
        "        # Verifica si el archivo se movió correctamente\n",
        "        if not os.path.exists(dest_path):\n",
        "            print(f\"Reintentando mover: {f}\")\n",
        "            shutil.move(src_path, dest_path)\n",
        "            # Da tiempo al sistema para procesar la operación\n",
        "            time.sleep(0.1)\n",
        "\n",
        "def move_data(SOURCE, TRAINING, VALIDATION, TEST, split_train=0.7, split_val_test=0.15):\n",
        "    files = [f for f in os.listdir(SOURCE) if os.path.isfile(os.path.join(SOURCE, f))]\n",
        "    print(f\"Total files found in {SOURCE}: {len(files)}\")  # Imprime el número total de archivos encontrados\n",
        "\n",
        "    random.shuffle(files)\n",
        "\n",
        "    train_size = int(len(files) * split_train)\n",
        "    val_size = int(len(files) * split_val_test)\n",
        "\n",
        "    train_files = files[:train_size]\n",
        "    val_files = files[train_size:train_size + val_size]\n",
        "    test_files = files[train_size + val_size:]\n",
        "\n",
        "    print(f\"Moving {len(train_files)} to {TRAINING}\")  # Imprime cuántos archivos se moverán al entrenamiento\n",
        "    print(f\"Moving {len(val_files)} to {VALIDATION}\")  # Imprime cuántos archivos se moverán a validación\n",
        "    print(f\"Moving {len(test_files)} to {TEST}\")  # Imprime cuántos archivos se moverán a prueba\n",
        "\n",
        "    # Mueve los archivos en lotes para evitar problemas con demasiadas operaciones a la vez\n",
        "    batch_size = 100  # Ajusta este tamaño según sea necesario\n",
        "    for i in range(0, len(train_files), batch_size):\n",
        "        move_files(train_files[i:i+batch_size], SOURCE, TRAINING)\n",
        "\n",
        "    for i in range(0, len(val_files), batch_size):\n",
        "        move_files(val_files[i:i+batch_size], SOURCE, VALIDATION)\n",
        "\n",
        "    for i in range(0, len(test_files), batch_size):\n",
        "        move_files(test_files[i:i+batch_size], SOURCE, TEST)\n",
        "\n",
        "# Ejecutar esta función para cada clase\n",
        "move_data(source_chimenea, train_chimenea_dir, val_chimenea_dir, test_chimenea_dir)\n",
        "move_data(source_no_chimenea, train_no_chimenea_dir, val_no_chimenea_dir, test_no_chimenea_dir)"
      ],
      "metadata": {
        "id": "twbvWtshnngg",
        "outputId": "e19ad8b7-1675-4b34-874c-ae6460479454",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files found in /content/drive/My Drive/sinrepco_fotos/chimenea: 3360\n",
            "Moving 2352 to /content/drive/My Drive/sinrepco_fotos/train/chimenea\n",
            "Moving 504 to /content/drive/My Drive/sinrepco_fotos/validation/chimenea\n",
            "Moving 504 to /content/drive/My Drive/sinrepco_fotos/test/chimenea\n",
            "Total files found in /content/drive/My Drive/sinrepco_fotos/no_chimenea: 3381\n",
            "Moving 2366 to /content/drive/My Drive/sinrepco_fotos/train/no_chimenea\n",
            "Moving 507 to /content/drive/My Drive/sinrepco_fotos/validation/no_chimenea\n",
            "Moving 508 to /content/drive/My Drive/sinrepco_fotos/test/no_chimenea\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.b. Después de dividir los datos, configuramos el ImageDataGenerator para cargar las imágenes de estas nuevas carpetas:"
      ],
      "metadata": {
        "id": "8yMhhElw4is4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importamos las bibliotecas necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Import the ImageDataGenerator class\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "# Parámetros (reducir estos valores si nos quedamos sin RAM)\n",
        "IMG_HEIGHT = 450\n",
        "IMG_WIDTH = 600\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    f'{base_dir}/train',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    f'{base_dir}/validation',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    f'{base_dir}/test',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "TcdEMJal4j_O",
        "outputId": "548d3a84-f8a9-402c-a8a3-8bdf50210322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4718 images belonging to 2 classes.\n",
            "Found 1011 images belonging to 2 classes.\n",
            "Found 1012 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Ahora definimos la arquitectura de la CNN. Tomamos una estructura de red neuronal convolucional, que es adecuada para el análisis de imágenes."
      ],
      "metadata": {
        "id": "DsbjWUhxNg3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Input\n",
        "\n",
        "# Definir la arquitectura de la CNN\n",
        "model = Sequential([\n",
        "    Input(shape=(450, 600, 3)),  # Especificamos la forma de entrada aquí\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1jK4njrJNjfT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Entrenamos** el modelo. Si bien el número de épocas recomendado normalmente (el número de veces que el modelo recorre todo el conjunto de datos para entrenarse) es de 20, usamos 6 para ajustarnos con el tiempo de ejecución máximo disponible (*ejecutar este código toma alrededor de 6 horas y 22 minutos*).\\\n",
        "Actualización: La [primera vez](https://github.com/fnovoas/sinrepco/blob/faf332cb9eff6f27528e503c696db6909bab49a5/Sinrepco.ipynb) que ejecutamos este código, encontramos que el modelo estaba clasificando incorrectamente la mayoría de las imágenes de la clase \"no_chimenea\" como \"chimenea\"; esto se debe al desequilibrio de clases en el conjunto de datos. Para compensar la falta de fotos de vehículos chimenea, aumentamos la cantidad de datos en la carpeta \"chimenea\" artificialmente como explicamos en el paso 2."
      ],
      "metadata": {
        "id": "aCGkIbuxlLDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 6\n",
        "\n",
        "# No funcionó ajustar los pesos según la proporción de las clases, dejaremos este código comentado\n",
        "# class_weight = {0: 12.0, 1: 1.0}\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS,\n",
        "#   class_weight=class_weight\n",
        ")"
      ],
      "metadata": {
        "id": "F43Er4cLlNNI",
        "outputId": "18985fa2-1db2-4fba-c623-36f537d28d38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7452s\u001b[0m 12s/step - accuracy: 0.7444 - loss: 0.6476 - val_accuracy: 0.9426 - val_loss: 0.1716\n",
            "Epoch 2/6\n",
            "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7235s\u001b[0m 12s/step - accuracy: 0.9604 - loss: 0.1241 - val_accuracy: 0.9822 - val_loss: 0.0712\n",
            "Epoch 3/6\n",
            "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7406s\u001b[0m 13s/step - accuracy: 0.9868 - loss: 0.0549 - val_accuracy: 0.9782 - val_loss: 0.1722\n",
            "Epoch 4/6\n",
            "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7323s\u001b[0m 12s/step - accuracy: 0.9877 - loss: 0.0485 - val_accuracy: 0.9713 - val_loss: 0.1381\n",
            "Epoch 5/6\n",
            "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7472s\u001b[0m 13s/step - accuracy: 0.9914 - loss: 0.0380 - val_accuracy: 0.9674 - val_loss: 0.2500\n",
            "Epoch 6/6\n",
            "\u001b[1m519/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:08\u001b[0m 12s/step - accuracy: 0.9976 - loss: 0.0115"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Evaluamos** el modelo.\n",
        "6.a. Gráficas de pérdida y precisión (*accuracy*)."
      ],
      "metadata": {
        "id": "vc5hRUmtlPQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Graficar los resultados del entrenamiento\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rbBEyXaXlUPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.b. Gráfica de matriz de confusión."
      ],
      "metadata": {
        "id": "5tf0rK4s3j5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Obtener predicciones del conjunto de prueba\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred = np.round(y_pred).astype(int).flatten()  # Redondear a 0 o 1\n",
        "\n",
        "# Obtener etiquetas verdaderas\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Etiquetas de las clases\n",
        "class_names = ['no_chimenea', 'chimenea']\n",
        "\n",
        "# Graficar la matriz de confusión\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pGhP9w5c3o4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.c. Curvas ROC y AUC."
      ],
      "metadata": {
        "id": "jWLPScBk3wnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Obtener probabilidades predichas\n",
        "y_pred_prob = model.predict(test_generator).flatten()\n",
        "\n",
        "# Calcular la curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Graficar la curva ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CCVS6zMU31cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.d. Reporte de clasificación."
      ],
      "metadata": {
        "id": "pTMt_ZbX32-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "id": "XRuFHQaW37XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.e. Curvas de pérdida y precisión **por época**."
      ],
      "metadata": {
        "id": "uKeiAnAh38dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lspWSryh4A6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.f. Gráfica de Precision-Recall"
      ],
      "metadata": {
        "id": "rx4WSZwi4EC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_true, y_pred_prob)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label='Precision-Recall curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N8TfjVXp4G5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Guardar** el modelo ya entrenado en Drive (para no tener que ejecutar el paso 5 nuevamente). *Tamaño del modelo actual: 2.89 GB*."
      ],
      "metadata": {
        "id": "lJVN2KdDnwNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo en formato Keras nativo en la carpeta sinrepco_fotos en Drive\n",
        "model_path = '/content/drive/My Drive/sinrepco_fotos/saved_model.keras'\n",
        "\n",
        "# Guardar el modelo entrenado en la ruta especificada\n",
        "model.save(model_path)\n"
      ],
      "metadata": {
        "id": "skpTlsO9n4YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.a. Descargar el modelo en el equipo local (más demorado)."
      ],
      "metadata": {
        "id": "XHNE5DpRsHE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo en formato Keras nativo en el almacenamiento local de Colab\n",
        "model_path = '/content/saved_model.keras'\n",
        "\n",
        "# Guardar el modelo entrenado en la ruta especificada\n",
        "model.save(model_path)\n",
        "\n",
        "# Descargar el modelo a tu equipo\n",
        "from google.colab import files\n",
        "files.download(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mmyVFH0UsQHg",
        "outputId": "b9f9541e-2f81-413f-9759-6b39477b0227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fb092a35-cfc3-4401-a5e6-6348e9741b17\", \"saved_model.keras\", 3101288695)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Cargar** el modelo a la sesión actual (para usar un modelo guardado anteriormente)."
      ],
      "metadata": {
        "id": "RjwAsyrcoBCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Cargar el modelo guardado\n",
        "model = load_model('/content/drive/My Drive/sinrepco_fotos/saved_model.keras')"
      ],
      "metadata": {
        "id": "IxFnr9Z5oKdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A continuación\n",
        "Deberemos desarrollar el subsistema de reconocimiento de placas vehiculares. Para un futuro avance, deberemos integrar los dos subsistemas y desarrollar la función de publicación automatizada en X (antes Twitter).\n",
        "Gracias por leer."
      ],
      "metadata": {
        "id": "IP46s_n7AiZr"
      }
    }
  ]
}