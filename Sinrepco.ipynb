{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fnovoas/sinrepco/blob/main/Sinrepco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SINREPCO\n",
        "por fnovoas@unal.edu.co"
      ],
      "metadata": {
        "id": "L3tPnZ558pQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cargar un modelo de Sinrepco ya hecho (entrenado), ejecutamos en orden los pasos **1**, **2.a.**, **8** y **3.b.**. Luego, podemos evaluarlo en el **paso 6**.\\\n",
        "Para crear y entrenar un modelo de Sinrepco nuevo, ejecutamos los pasos en orden en la misma sesión."
      ],
      "metadata": {
        "id": "znIPoKDs4Nk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Instalamos e importamos las bibliotecas necesarias: TensorFlow para el desarrollo de modelos de inteligencia artificial, OpenCV para el procesamiento de imágenes y Tesseract para el reconocimiento óptico de caracteres (OCR)."
      ],
      "metadata": {
        "id": "VSwHf7ak8b99"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vQvguu1Q6a7a",
        "outputId": "aab479bd-f8f5-45f5-ff7c-0cfaeb3d39d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow opencv-python pytesseract\n",
        "#importamos las bibliotecas necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 2.a. Procedemos con la recolección de datos, reunimos un conjunto de datos que contiene imágenes de vehículos, tanto contaminantes como no contaminantes, estas imágenes fueron capturadas por mí en diversas ubicaciones. Contamos con 3509 imágenes de vehículos no chimenea y 615 imágenes de vehículos chimenea.\n",
        "Separamos las imágenes manualmente (por inspección) según si contienen vehículos que emiten humo visible o no, en dos carpetas: \"chimenea\" y \"no_chimenea\", contenidas en un directorio raíz \"sinrepco_fotos\" en mi unidad de Drive. Con estos datos entrenaremos al modelo.\\\n",
        "Montamos Drive para acceder a las imágenes.\n"
      ],
      "metadata": {
        "id": "mkPe4Udv9xZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar el Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Directorio base donde está la carpeta \"sinrepco_fotos\"\n",
        "base_dir = \"/content/drive/My Drive/sinrepco_fotos\"\n",
        "\n",
        "# Función para contar archivos en una carpeta\n",
        "def contar_archivos_en_carpeta(carpeta):\n",
        "    return len([f for f in os.listdir(carpeta) if os.path.isfile(os.path.join(carpeta, f))])\n",
        "\n",
        "# Recorrer todas las carpetas y subcarpetas en el directorio base\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    for dir_name in dirs:\n",
        "        carpeta_actual = os.path.join(root, dir_name)\n",
        "        num_archivos = contar_archivos_en_carpeta(carpeta_actual)\n",
        "        print(f\"Carpeta encontrada: {carpeta_actual} - Archivos: {num_archivos}\")\n",
        "\n",
        "# Función para cambiar extensión .JPG a .jpg en una carpeta y sus subcarpetas\n",
        "def cambiar_extensiones_a_minusculas(carpeta):\n",
        "    cambios_realizados = False\n",
        "    for root, dirs, files in os.walk(carpeta):\n",
        "        for filename in files:\n",
        "            if filename.endswith(\".JPG\"):\n",
        "                old_file = os.path.join(root, filename)\n",
        "                new_file = os.path.join(root, filename.lower())\n",
        "                os.rename(old_file, new_file)\n",
        "                cambios_realizados = True\n",
        "    if cambios_realizados:\n",
        "        print(\"Extensiones de archivo cambiadas de .JPG a .jpg.\")\n",
        "\n",
        "# Aplicar cambio de extensiones en la raíz y en todas las subcarpetas\n",
        "cambiar_extensiones_a_minusculas(base_dir)\n",
        "\n",
        "# Verificar cuántas imágenes hay en cada carpeta\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    for dir_name in dirs:\n",
        "        carpeta_actual = os.path.join(root, dir_name)\n",
        "        num_archivos = len([f for f in os.listdir(carpeta_actual) if os.path.isfile(os.path.join(carpeta_actual, f))])\n",
        "        print(f\"Archivos en {carpeta_actual}: {num_archivos}\")\n"
      ],
      "metadata": {
        "id": "Fs2QnY1LnLWe",
        "outputId": "57eb3d0d-1c69-4c53-f7e4-0f1b86a9739c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/chimenea - Archivos: 615\n",
            "Carpeta encontrada: /content/drive/My Drive/sinrepco_fotos/no_chimenea - Archivos: 3509\n",
            "Extensiones de archivo cambiadas de .JPG a .jpg.\n",
            "Archivos en /content/drive/My Drive/sinrepco_fotos/chimenea: 615\n",
            "Archivos en /content/drive/My Drive/sinrepco_fotos/no_chimenea: 3509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.b. **(Solo hace falta ejecutar este código si no tenemos suficientes imágenes de vehículos chimenea)** Actualización: La [primera vez](https://github.com/fnovoas/sinrepco/blob/faf332cb9eff6f27528e503c696db6909bab49a5/Sinrepco.ipynb) que ejecutamos el paso 5, encontramos que el modelo estaba clasificando incorrectamente la mayoría de las imágenes de la clase \"no_chimenea\" como \"chimenea\"; esto se debe al desequilibrio de clases en el conjunto de datos. Para compensar la falta de fotos de vehículos chimenea, **generamos imágenes sintéticamente** (a partir de las imágenes existentes) para guardarlas en la carpeta \"chimenea\". Eliminaremos este paso una vez que hayamos aumentado la cantidad de datos de vehículos chimenea (esto es, cuando les tome más fotos)."
      ],
      "metadata": {
        "id": "n_45SniL4KRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "# Directorio de la carpeta chimenea\n",
        "chimenea_dir = f'{base_dir}/chimenea'\n",
        "\n",
        "# Configuración del ImageDataGenerator para aumentar datos\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=12,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.05,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Cargar imágenes desde la carpeta chimenea\n",
        "for filename in os.listdir(chimenea_dir):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        img_path = os.path.join(chimenea_dir, filename)\n",
        "        img = tf.keras.preprocessing.image.load_img(img_path)\n",
        "        x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "        x = x.reshape((1,) + x.shape)  # Redimensionar para el generador\n",
        "\n",
        "        # Generar 4 imágenes sintéticas por cada imagen original\n",
        "        i = 0\n",
        "        for batch in datagen.flow(x, batch_size=1, save_to_dir=chimenea_dir, save_prefix=f'aug_{i}_{int(time.time())}', save_format='jpg'):\n",
        "            i += 1\n",
        "            time.sleep(0.3)  # Esperar 0.3 segundos antes de generar la siguiente imagen\n",
        "            if i >= 4:\n",
        "                break\n",
        "\n",
        "# Contar y mostrar el número total de imágenes en la carpeta chimenea\n",
        "print(\"Imágenes sintéticas generadas.\")\n",
        "time.sleep(10)  # Esperar 10 segundos\n",
        "total_files = len(os.listdir(chimenea_dir))\n",
        "print(f\"Total de archivos encontrados en {chimenea_dir}: {total_files}\")\n"
      ],
      "metadata": {
        "id": "d3OhO9RXnaAR",
        "outputId": "db29a58b-a8e0-4ce4-b4f2-c07de9b21d80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imágenes sintéticas generadas.\n",
            "Total de archivos encontrados en /content/drive/My Drive/sinrepco_fotos/chimenea: 3075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 3.a. **(Solo hace falta ejecutar este código cada vez que incorporemos nuevos datos, al hacerlo, deben estar guardados en las carpetas originales \"chimenea\" y \"no_chimenea\" en el directorio raíz respectivamente)** Cargamos y preparamos los datos de la carpeta en donde están almacenados en Drive. Este código divide las imágenes en conjuntos de entrenamiento, validación y prueba según el porcentaje especificado: el 70% de los datos irán en entrenamiento y el 15% en cada una de las otras dos categorías. Ejecutar este código cambia la estructura de la organización de los archivos y carpetas en Drive."
      ],
      "metadata": {
        "id": "4fB5L0_InkqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "# Crear directorios si no existen\n",
        "base_dir = '/content/drive/My Drive/sinrepco_fotos'\n",
        "source_chimenea = f'{base_dir}/chimenea'\n",
        "source_no_chimenea = f'{base_dir}/no_chimenea'\n",
        "\n",
        "train_chimenea_dir = f'{base_dir}/train/chimenea'\n",
        "val_chimenea_dir = f'{base_dir}/validation/chimenea'\n",
        "test_chimenea_dir = f'{base_dir}/test/chimenea'\n",
        "\n",
        "train_no_chimenea_dir = f'{base_dir}/train/no_chimenea'\n",
        "val_no_chimenea_dir = f'{base_dir}/validation/no_chimenea'\n",
        "test_no_chimenea_dir = f'{base_dir}/test/no_chimenea'\n",
        "\n",
        "os.makedirs(train_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(val_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(test_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(train_no_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(val_no_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(test_no_chimenea_dir, exist_ok=True)\n",
        "\n",
        "def move_files(files, source, destination):\n",
        "    for f in files:\n",
        "        src_path = os.path.join(source, f)\n",
        "        dest_path = os.path.join(destination, f)\n",
        "        shutil.move(src_path, dest_path)\n",
        "        # Verifica si el archivo se movió correctamente\n",
        "        if not os.path.exists(dest_path):\n",
        "            print(f\"Reintentando mover: {f}\")\n",
        "            shutil.move(src_path, dest_path)\n",
        "            # Da tiempo al sistema para procesar la operación\n",
        "            time.sleep(0.5)\n",
        "\n",
        "def move_data(SOURCE, TRAINING, VALIDATION, TEST, split_train=0.7, split_val_test=0.15):\n",
        "    files = [f for f in os.listdir(SOURCE) if os.path.isfile(os.path.join(SOURCE, f))]\n",
        "    print(f\"Total de archivos encontrados en {SOURCE}: {len(files)}\")  # Imprime el número total de archivos encontrados\n",
        "\n",
        "    random.shuffle(files)\n",
        "\n",
        "    train_size = int(len(files) * split_train)\n",
        "    val_size = int(len(files) * split_val_test)\n",
        "\n",
        "    train_files = files[:train_size]\n",
        "    val_files = files[train_size:train_size + val_size]\n",
        "    test_files = files[train_size + val_size:]\n",
        "\n",
        "    print(f\"Moviendo {len(train_files)} archivos a {TRAINING}\")  # Imprime cuántos archivos se moverán al entrenamiento\n",
        "    print(f\"Moviendo {len(val_files)} archivos a {VALIDATION}\")  # Imprime cuántos archivos se moverán a validación\n",
        "    print(f\"Moviendo {len(test_files)} archivos a {TEST}\")  # Imprime cuántos archivos se moverán a prueba\n",
        "\n",
        "    # Mueve los archivos en lotes para evitar problemas con demasiadas operaciones a la vez\n",
        "    batch_size = 100  # Ajusta este tamaño según sea necesario\n",
        "    for i in range(0, len(train_files), batch_size):\n",
        "        move_files(train_files[i:i+batch_size], SOURCE, TRAINING)\n",
        "\n",
        "    for i in range(0, len(val_files), batch_size):\n",
        "        move_files(val_files[i:i+batch_size], SOURCE, VALIDATION)\n",
        "\n",
        "    for i in range(0, len(test_files), batch_size):\n",
        "        move_files(test_files[i:i+batch_size], SOURCE, TEST)\n",
        "\n",
        "# Ejecutar esta función para cada clase\n",
        "move_data(source_chimenea, train_chimenea_dir, val_chimenea_dir, test_chimenea_dir)\n",
        "move_data(source_no_chimenea, train_no_chimenea_dir, val_no_chimenea_dir, test_no_chimenea_dir)"
      ],
      "metadata": {
        "id": "twbvWtshnngg",
        "outputId": "1b9a53a0-3cfa-4236-bf1b-681fca3cd7b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de archivos encontrados en /content/drive/My Drive/sinrepco_fotos/chimenea: 3075\n",
            "Moviendo 2152 archivos a /content/drive/My Drive/sinrepco_fotos/train/chimenea\n",
            "Moviendo 461 archivos a /content/drive/My Drive/sinrepco_fotos/validation/chimenea\n",
            "Moviendo 462 archivos a /content/drive/My Drive/sinrepco_fotos/test/chimenea\n",
            "Total de archivos encontrados en /content/drive/My Drive/sinrepco_fotos/no_chimenea: 3509\n",
            "Moviendo 2456 archivos a /content/drive/My Drive/sinrepco_fotos/train/no_chimenea\n",
            "Moviendo 526 archivos a /content/drive/My Drive/sinrepco_fotos/validation/no_chimenea\n",
            "Moviendo 527 archivos a /content/drive/My Drive/sinrepco_fotos/test/no_chimenea\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.b. Después de dividir los datos, configuramos el ImageDataGenerator para cargar las imágenes de estas nuevas carpetas:"
      ],
      "metadata": {
        "id": "8yMhhElw4is4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importamos las bibliotecas necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Import the ImageDataGenerator class\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "print('Los generadores de datos de entrenamiento, validación y prueba encontraron, respectivamente:\\n')\n",
        "# Parámetros (reducir estos valores si nos quedamos sin RAM)\n",
        "IMG_HEIGHT = 450\n",
        "IMG_WIDTH = 600\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    f'{base_dir}/train',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    f'{base_dir}/validation',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    f'{base_dir}/test',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "TcdEMJal4j_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Ahora definimos la arquitectura de la CNN. Tomamos una estructura de red neuronal convolucional, que es adecuada para el análisis de imágenes."
      ],
      "metadata": {
        "id": "DsbjWUhxNg3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Input\n",
        "\n",
        "# Definir la arquitectura de la CNN\n",
        "model = Sequential([\n",
        "    Input(shape=(450, 600, 3)),  # Especificamos la forma de entrada aquí\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1jK4njrJNjfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Entrenamos el modelo. Si bien el número de épocas recomendado normalmente (el número de veces que el modelo recorre todo el conjunto de datos para entrenarse) es de 20, usamos 7 para ajustarnos con el tiempo de ejecución máximo disponible (12h). *Ejecutar este código tomó máximo 11 horas y 42 minutos*."
      ],
      "metadata": {
        "id": "aCGkIbuxlLDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 7\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "id": "F43Er4cLlNNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Evaluamos** el modelo.\n",
        "6.a. Gráficas de pérdida y precisión (*accuracy*)."
      ],
      "metadata": {
        "id": "vc5hRUmtlPQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Graficar los resultados del entrenamiento\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rbBEyXaXlUPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.b. Gráfica de matriz de confusión."
      ],
      "metadata": {
        "id": "5tf0rK4s3j5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Obtener predicciones del conjunto de prueba\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred = np.round(y_pred).astype(int).flatten()  # Redondear a 0 o 1\n",
        "\n",
        "# Obtener etiquetas verdaderas\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Etiquetas de las clases\n",
        "class_names = ['no_chimenea', 'chimenea']\n",
        "\n",
        "# Graficar la matriz de confusión\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pGhP9w5c3o4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.c. Curvas ROC y AUC."
      ],
      "metadata": {
        "id": "jWLPScBk3wnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Obtener probabilidades predichas\n",
        "y_pred_prob = model.predict(test_generator).flatten()\n",
        "\n",
        "# Definir y_true con las etiquetas verdaderas\n",
        "y_true = test_generator.classes  # Obtiene las etiquetas verdaderas del generador de prueba\n",
        "\n",
        "# Calcular la curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Graficar la curva ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CCVS6zMU31cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.d. Reporte de clasificación."
      ],
      "metadata": {
        "id": "pTMt_ZbX32-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# Obtener predicciones binarizadas (0 o 1)\n",
        "y_pred = np.round(y_pred_prob).astype(int)\n",
        "\n",
        "# Etiquetas de las clases\n",
        "class_names = ['no_chimenea', 'chimenea']\n",
        "\n",
        "# Generar y mostrar el reporte de clasificación\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "id": "XRuFHQaW37XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.e. Curvas de pérdida y precisión **por época**. Este paso requiere acceso al historial de entrenamiento del modelo *(archivo history.npy)*. Si el modelo fue entrenado en esta misma sesión, mantenemos la segunda línea comentada."
      ],
      "metadata": {
        "id": "uKeiAnAh38dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el historial de entrenamiento desde el archivo\n",
        "#history = np.load('/content/drive/My Drive/sinrepco_fotos/history.npy', allow_pickle=True).item() # Descomentar esta línea solo si estamos cargando un modelo creado en una sesión anterior\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lspWSryh4A6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.f. Gráfica de Precision-Recall."
      ],
      "metadata": {
        "id": "rx4WSZwi4EC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_true, y_pred_prob)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label='Precision-Recall curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N8TfjVXp4G5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. 7.a. **Guardar** el modelo ya entrenado en Drive (para no tener que ejecutar el paso 5 nuevamente). *Tamaño del modelo actual: 2.89 GB*."
      ],
      "metadata": {
        "id": "lJVN2KdDnwNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo en formato Keras nativo en la carpeta sinrepco_Fotos en Drive\n",
        "model_path = '/content/drive/My Drive/sinrepco_fotos/saved_model.keras'\n",
        "\n",
        "# Guardar el modelo entrenado en la ruta especificada\n",
        "model.save(model_path)\n"
      ],
      "metadata": {
        "id": "skpTlsO9n4YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.b. Guardar el historial de entrenamiento del modelo en Drive (*para cargarlo y usarlo en el paso 6.e.*)."
      ],
      "metadata": {
        "id": "4A-NIg0zTdxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el historial en un archivo .npy\n",
        "np.save('/content/drive/My Drive/sinrepco_fotos/history.npy', history.history)"
      ],
      "metadata": {
        "id": "LaBqkgdHTlvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.c. Descargar el modelo en el equipo local (más demorado)."
      ],
      "metadata": {
        "id": "XHNE5DpRsHE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo en formato Keras nativo en el almacenamiento local de Colab\n",
        "model_path = '/content/saved_model.keras'\n",
        "\n",
        "# Guardar el modelo entrenado en la ruta especificada\n",
        "model.save(model_path)\n",
        "\n",
        "# Descargar el modelo a tu equipo\n",
        "from google.colab import files\n",
        "files.download(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mmyVFH0UsQHg",
        "outputId": "b9f9541e-2f81-413f-9759-6b39477b0227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fb092a35-cfc3-4401-a5e6-6348e9741b17\", \"saved_model.keras\", 3101288695)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Cargar** el modelo a la sesión actual (para usar un modelo guardado anteriormente)."
      ],
      "metadata": {
        "id": "RjwAsyrcoBCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Cargar el modelo guardado\n",
        "model = load_model('/content/drive/My Drive/sinrepco_fotos/saved_model.keras')"
      ],
      "metadata": {
        "id": "IxFnr9Z5oKdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A continuación\n",
        "Deberemos desarrollar el subsistema de reconocimiento de placas vehiculares. Para futuras fases, deberemos integrar los dos subsistemas y desarrollar la función de publicación automatizada en X (antes Twitter).\n",
        "Gracias por leer."
      ],
      "metadata": {
        "id": "IP46s_n7AiZr"
      }
    }
  ]
}