{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fnovoas/sinrepco/blob/main/Sinrepco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SINREPCO\n",
        "por fnovoas@unal.edu.co"
      ],
      "metadata": {
        "id": "L3tPnZ558pQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cargar un modelo de Sinrepco ya hecho (entrenado), saltamos directamente al **paso 8**. Podemos evaluarlo en el **paso 6**."
      ],
      "metadata": {
        "id": "znIPoKDs4Nk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Instalamos e importamos las bibliotecas necesarias: TensorFlow para el desarrollo de modelos de inteligencia artificial, OpenCV para el procesamiento de imágenes y Tesseract para el reconocimiento óptico de caracteres (OCR)."
      ],
      "metadata": {
        "id": "VSwHf7ak8b99"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQvguu1Q6a7a"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow opencv-python pytesseract\n",
        "#importamos las bibliotecas necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 2.a. Procedemos con la recolección de datos, reunimos un conjunto de datos que contiene imágenes de vehículos, tanto contaminantes como no contaminantes, estas imágenes fueron capturadas por mí en diversas ubicaciones. Contamos con 3396 imágenes de vehículos no chimenea y 298 imágenes de vehículos chimenea.\n",
        "Separamos las imágenes manualmente (por inspección) según si contienen vehículos que emiten humo visible o no, en dos carpetas: \"chimenea\" y \"no_chimenea\", contenidas en un directorio raíz \"sinrepco_fotos\" en mi unidad de Drive. Con estos datos entrenaremos al modelo.\\\n",
        "Montamos Drive para acceder a las imágenes.\n"
      ],
      "metadata": {
        "id": "mkPe4Udv9xZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar el Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Directorio base donde está la carpeta \"sinrepco_fotos\"\n",
        "base_dir = \"/content/drive/My Drive/sinrepco_fotos\"\n",
        "\n",
        "# Función para contar archivos en una carpeta\n",
        "def contar_archivos_en_carpeta(carpeta):\n",
        "    return len([f for f in os.listdir(carpeta) if os.path.isfile(os.path.join(carpeta, f))])\n",
        "\n",
        "# Recorrer todas las carpetas y subcarpetas en el directorio base\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    for dir_name in dirs:\n",
        "        carpeta_actual = os.path.join(root, dir_name)\n",
        "        num_archivos = contar_archivos_en_carpeta(carpeta_actual)\n",
        "        print(f\"Carpeta encontrada: {carpeta_actual} - Archivos: {num_archivos}\")\n",
        "\n",
        "# Función para cambiar extensión .JPG a .jpg en una carpeta y sus subcarpetas\n",
        "def cambiar_extensiones_a_minusculas(carpeta):\n",
        "    cambios_realizados = False\n",
        "    for root, dirs, files in os.walk(carpeta):\n",
        "        for filename in files:\n",
        "            if filename.endswith(\".JPG\"):\n",
        "                old_file = os.path.join(root, filename)\n",
        "                new_file = os.path.join(root, filename.lower())\n",
        "                os.rename(old_file, new_file)\n",
        "                cambios_realizados = True\n",
        "    if cambios_realizados:\n",
        "        print(\"Extensiones de archivo cambiadas de .JPG a .jpg.\")\n",
        "\n",
        "# Aplicar cambio de extensiones en la raíz y en todas las subcarpetas\n",
        "cambiar_extensiones_a_minusculas(base_dir)\n",
        "\n",
        "# Verificar cuántas imágenes hay en cada carpeta\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    for dir_name in dirs:\n",
        "        carpeta_actual = os.path.join(root, dir_name)\n",
        "        num_archivos = len([f for f in os.listdir(carpeta_actual) if os.path.isfile(os.path.join(carpeta_actual, f))])\n",
        "        print(f\"Archivos en {carpeta_actual}: {num_archivos}\")\n"
      ],
      "metadata": {
        "id": "Fs2QnY1LnLWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.b. **(Solo hace falta ejecutar este código si no tenemos suficientes imágenes de vehículos chimenea)** Actualización: La [primera vez](https://github.com/fnovoas/sinrepco/blob/faf332cb9eff6f27528e503c696db6909bab49a5/Sinrepco.ipynb) que ejecutamos el paso 5, encontramos que el modelo estaba clasificando incorrectamente la mayoría de las imágenes de la clase \"no_chimenea\" como \"chimenea\"; esto se debe al desequilibrio de clases en el conjunto de datos. Para compensar la falta de fotos de vehículos chimenea, **generamos imágenes sintéticamente** (a partir de las imágenes existentes) para guardarlas en la carpeta \"chimenea\". Eliminaremos este paso una vez que hayamos aumentado la cantidad de datos de vehículos chimenea (esto es, cuando les tome más fotos)."
      ],
      "metadata": {
        "id": "n_45SniL4KRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "# Directorio de la carpeta chimenea\n",
        "chimenea_dir = f'{base_dir}/chimenea'\n",
        "\n",
        "# Configuración del ImageDataGenerator para aumentar datos\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=12,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.05,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Cargar imágenes desde la carpeta chimenea\n",
        "for filename in os.listdir(chimenea_dir):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        img_path = os.path.join(chimenea_dir, filename)\n",
        "        img = tf.keras.preprocessing.image.load_img(img_path)\n",
        "        x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "        x = x.reshape((1,) + x.shape)  # Redimensionar para el generador\n",
        "\n",
        "        # Generar 10 imágenes sintéticas por cada imagen original\n",
        "        i = 0\n",
        "        for batch in datagen.flow(x, batch_size=1, save_to_dir=chimenea_dir, save_prefix=f'aug_{i}_{int(time.time())}', save_format='jpg'):\n",
        "            i += 1\n",
        "            time.sleep(0.3)  # Esperar 0.3 segundos antes de generar la siguiente imagen\n",
        "            if i >= 10:\n",
        "                break\n",
        "\n",
        "# Contar y mostrar el número total de imágenes en la carpeta chimenea\n",
        "print(\"Imágenes sintéticas generadas.\")\n",
        "time.sleep(10)  # Esperar 10 segundos\n",
        "total_files = len(os.listdir(chimenea_dir))\n",
        "print(f\"Total de archivos encontrados en {chimenea_dir}: {total_files}\")\n"
      ],
      "metadata": {
        "id": "d3OhO9RXnaAR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 3.a. **(Solo hace falta ejecutar este código cada vez que incorporemos nuevos datos, al hacerlo, deben estar guardados en las carpetas originales \"chimenea\" y \"no_chimenea\" en el directorio raíz respectivamente)** Cargamos y preparamos los datos de la carpeta en donde están almacenados en Drive. Este código divide las imágenes en conjuntos de entrenamiento, validación y prueba según el porcentaje especificado: el 70% de los datos irán en entrenamiento y el 15% en cada una de las otras dos categorías. Ejecutar este código cambia la estructura de la organización de los archivos y carpetas en Drive."
      ],
      "metadata": {
        "id": "4fB5L0_InkqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "# Crear directorios si no existen\n",
        "base_dir = '/content/drive/My Drive/sinrepco_fotos'\n",
        "source_chimenea = f'{base_dir}/chimenea'\n",
        "source_no_chimenea = f'{base_dir}/no_chimenea'\n",
        "\n",
        "train_chimenea_dir = f'{base_dir}/train/chimenea'\n",
        "val_chimenea_dir = f'{base_dir}/validation/chimenea'\n",
        "test_chimenea_dir = f'{base_dir}/test/chimenea'\n",
        "\n",
        "train_no_chimenea_dir = f'{base_dir}/train/no_chimenea'\n",
        "val_no_chimenea_dir = f'{base_dir}/validation/no_chimenea'\n",
        "test_no_chimenea_dir = f'{base_dir}/test/no_chimenea'\n",
        "\n",
        "os.makedirs(train_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(val_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(test_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(train_no_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(val_no_chimenea_dir, exist_ok=True)\n",
        "os.makedirs(test_no_chimenea_dir, exist_ok=True)\n",
        "\n",
        "def move_files(files, source, destination):\n",
        "    for f in files:\n",
        "        src_path = os.path.join(source, f)\n",
        "        dest_path = os.path.join(destination, f)\n",
        "        shutil.move(src_path, dest_path)\n",
        "        # Verifica si el archivo se movió correctamente\n",
        "        if not os.path.exists(dest_path):\n",
        "            print(f\"Reintentando mover: {f}\")\n",
        "            shutil.move(src_path, dest_path)\n",
        "            # Da tiempo al sistema para procesar la operación\n",
        "            time.sleep(0.5)\n",
        "\n",
        "def move_data(SOURCE, TRAINING, VALIDATION, TEST, split_train=0.7, split_val_test=0.15):\n",
        "    files = [f for f in os.listdir(SOURCE) if os.path.isfile(os.path.join(SOURCE, f))]\n",
        "    print(f\"Total de archivos encontrados en {SOURCE}: {len(files)}\")  # Imprime el número total de archivos encontrados\n",
        "\n",
        "    random.shuffle(files)\n",
        "\n",
        "    train_size = int(len(files) * split_train)\n",
        "    val_size = int(len(files) * split_val_test)\n",
        "\n",
        "    train_files = files[:train_size]\n",
        "    val_files = files[train_size:train_size + val_size]\n",
        "    test_files = files[train_size + val_size:]\n",
        "\n",
        "    print(f\"Moviendo {len(train_files)} archivos a {TRAINING}\")  # Imprime cuántos archivos se moverán al entrenamiento\n",
        "    print(f\"Moviendo {len(val_files)} archivos a {VALIDATION}\")  # Imprime cuántos archivos se moverán a validación\n",
        "    print(f\"Moviendo {len(test_files)} archivos a {TEST}\")  # Imprime cuántos archivos se moverán a prueba\n",
        "\n",
        "    # Mueve los archivos en lotes para evitar problemas con demasiadas operaciones a la vez\n",
        "    batch_size = 100  # Ajusta este tamaño según sea necesario\n",
        "    for i in range(0, len(train_files), batch_size):\n",
        "        move_files(train_files[i:i+batch_size], SOURCE, TRAINING)\n",
        "\n",
        "    for i in range(0, len(val_files), batch_size):\n",
        "        move_files(val_files[i:i+batch_size], SOURCE, VALIDATION)\n",
        "\n",
        "    for i in range(0, len(test_files), batch_size):\n",
        "        move_files(test_files[i:i+batch_size], SOURCE, TEST)\n",
        "\n",
        "# Ejecutar esta función para cada clase\n",
        "move_data(source_chimenea, train_chimenea_dir, val_chimenea_dir, test_chimenea_dir)\n",
        "move_data(source_no_chimenea, train_no_chimenea_dir, val_no_chimenea_dir, test_no_chimenea_dir)"
      ],
      "metadata": {
        "id": "twbvWtshnngg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.b. Después de dividir los datos, configuramos el ImageDataGenerator para cargar las imágenes de estas nuevas carpetas:"
      ],
      "metadata": {
        "id": "8yMhhElw4is4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importamos las bibliotecas necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Import the ImageDataGenerator class\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "# Parámetros (reducir estos valores si nos quedamos sin RAM)\n",
        "IMG_HEIGHT = 450\n",
        "IMG_WIDTH = 600\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    f'{base_dir}/train',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    f'{base_dir}/validation',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    f'{base_dir}/test',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "TcdEMJal4j_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Ahora definimos la arquitectura de la CNN. Tomamos una estructura de red neuronal convolucional, que es adecuada para el análisis de imágenes."
      ],
      "metadata": {
        "id": "DsbjWUhxNg3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Input\n",
        "\n",
        "# Definir la arquitectura de la CNN\n",
        "model = Sequential([\n",
        "    Input(shape=(450, 600, 3)),  # Especificamos la forma de entrada aquí\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1jK4njrJNjfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Entrenamos el modelo. Si bien el número de épocas recomendado normalmente (el número de veces que el modelo recorre todo el conjunto de datos para entrenarse) es de 20, usamos 7 para ajustarnos con el tiempo de ejecución máximo disponible."
      ],
      "metadata": {
        "id": "aCGkIbuxlLDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 7\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "id": "F43Er4cLlNNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Evaluamos** el modelo.\n",
        "6.a. Gráficas de pérdida y precisión (*accuracy*)."
      ],
      "metadata": {
        "id": "vc5hRUmtlPQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Graficar los resultados del entrenamiento\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rbBEyXaXlUPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.b. Gráfica de matriz de confusión."
      ],
      "metadata": {
        "id": "5tf0rK4s3j5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Obtener predicciones del conjunto de prueba\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred = np.round(y_pred).astype(int).flatten()  # Redondear a 0 o 1\n",
        "\n",
        "# Obtener etiquetas verdaderas\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Etiquetas de las clases\n",
        "class_names = ['no_chimenea', 'chimenea']\n",
        "\n",
        "# Graficar la matriz de confusión\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pGhP9w5c3o4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.c. Curvas ROC y AUC."
      ],
      "metadata": {
        "id": "jWLPScBk3wnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Obtener probabilidades predichas\n",
        "y_pred_prob = model.predict(test_generator).flatten()\n",
        "\n",
        "# Calcular la curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Graficar la curva ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CCVS6zMU31cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.d. Reporte de clasificación."
      ],
      "metadata": {
        "id": "pTMt_ZbX32-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "id": "XRuFHQaW37XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.e. Curvas de pérdida y precisión **por época**."
      ],
      "metadata": {
        "id": "uKeiAnAh38dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lspWSryh4A6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.f. Gráfica de Precision-Recall"
      ],
      "metadata": {
        "id": "rx4WSZwi4EC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_true, y_pred_prob)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label='Precision-Recall curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N8TfjVXp4G5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Guardar** el modelo ya entrenado en Drive (para no tener que ejecutar el paso 5 nuevamente). *Tamaño del modelo actual: 2.89 GB*."
      ],
      "metadata": {
        "id": "lJVN2KdDnwNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo en formato Keras nativo en la carpeta sinrepco_Fotos en Drive\n",
        "model_path = '/content/drive/My Drive/sinrepco_fotos/saved_model.keras'\n",
        "\n",
        "# Guardar el modelo entrenado en la ruta especificada\n",
        "model.save(model_path)\n"
      ],
      "metadata": {
        "id": "skpTlsO9n4YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.a. Descargar el modelo en el equipo local (más demorado)."
      ],
      "metadata": {
        "id": "XHNE5DpRsHE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo en formato Keras nativo en el almacenamiento local de Colab\n",
        "model_path = '/content/saved_model.keras'\n",
        "\n",
        "# Guardar el modelo entrenado en la ruta especificada\n",
        "model.save(model_path)\n",
        "\n",
        "# Descargar el modelo a tu equipo\n",
        "from google.colab import files\n",
        "files.download(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mmyVFH0UsQHg",
        "outputId": "b9f9541e-2f81-413f-9759-6b39477b0227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fb092a35-cfc3-4401-a5e6-6348e9741b17\", \"saved_model.keras\", 3101288695)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Cargar** el modelo a la sesión actual (para usar un modelo guardado anteriormente)."
      ],
      "metadata": {
        "id": "RjwAsyrcoBCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Cargar el modelo guardado\n",
        "model = load_model('/content/drive/My Drive/sinrepco_fotos/saved_model.keras')"
      ],
      "metadata": {
        "id": "IxFnr9Z5oKdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A continuación\n",
        "Deberemos desarrollar el subsistema de reconocimiento de placas vehiculares. Para un futuro avance, deberemos integrar los dos subsistemas y desarrollar la función de publicación automatizada en X (antes Twitter).\n",
        "Gracias por leer."
      ],
      "metadata": {
        "id": "IP46s_n7AiZr"
      }
    }
  ]
}